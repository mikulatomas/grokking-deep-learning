{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_mnist import init, load\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case that dataset is missing or pickle is broken uncomment this\n",
    "# init()\n",
    "\n",
    "x_train, y_train, x_test, y_test = load()\n",
    "\n",
    "# take first 1000 samples\n",
    "x_train = x_train[0:1000]\n",
    "y_train = y_train[0:1000]\n",
    "\n",
    "# transform labels from [2] to [0,0,1,0,0,0,0,0,0,0]\n",
    "OUT_CLASSES = 10\n",
    "\n",
    "transformed_y_train = []\n",
    "\n",
    "for y_label in y_train:\n",
    "    zero = np.zeros((OUT_CLASSES,))\n",
    "    zero[y_label] = 1\n",
    "    transformed_y_train.append(zero)\n",
    "\n",
    "y_train = transformed_y_train\n",
    "\n",
    "transformed_y_test = []\n",
    "\n",
    "for y_label in y_test:\n",
    "    zero = np.zeros((OUT_CLASSES,))\n",
    "    zero[y_label] = 1\n",
    "    transformed_y_test.append(zero)\n",
    "\n",
    "y_test = transformed_y_test\n",
    "\n",
    "# normalize input, avoid divergence\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return x > 0\n",
    "\n",
    "def predict(input_data, weights):\n",
    "    # input dot weights between 0 and 1 layer\n",
    "    # (1, 783) dot (738, 30) -> (1, 30)\n",
    "    layer_1 = relu(np.dot(input_data, weights[0]))\n",
    "    # output from layer 1 dot weights between 1 and 2 layer\n",
    "    # (1, 30) dot (30, 10) -> (1, 10)\n",
    "    layer_2 = np.dot(layer_1, weights[1])\n",
    "    \n",
    "    return layer_1, layer_2\n",
    "\n",
    "# calculate accuracy\n",
    "def accuracy(x_train, y_train, weights):\n",
    "    match = 0\n",
    "    for input_, label in zip(x_train, y_train):\n",
    "        _, output = predict(input_, weights)\n",
    "        \n",
    "        if np.argmax(output) == np.argmax(label):\n",
    "            match += 1\n",
    "\n",
    "    return match / len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00137727, -0.07026133,  0.07340835, -0.03961604, -0.31971186,\n",
       "       -0.16583885,  0.21613118, -0.06522297, -0.05437205, -0.19227169])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input layer\n",
    "LAYER_0_NODES = x_train.shape[1]\n",
    "# hidden layer\n",
    "LAYER_1_NODES = 100\n",
    "# output layer\n",
    "LAYER_2_NODES = 10\n",
    "\n",
    "# init weights (-0.1 to 0.1 range)\n",
    "init_weights_0_1 = 0.2 * np.random.rand(LAYER_0_NODES, LAYER_1_NODES) - 0.1\n",
    "init_weights_1_2 = 0.2 * np.random.rand(LAYER_1_NODES, LAYER_2_NODES) - 0.1\n",
    "\n",
    "# random prediction\n",
    "_ , result = predict(x_train[0], (init_weights_0_1, init_weights_1_2))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, train_labels, init_weights, alpha, number_of_epoch):\n",
    "    weights_0_1 = init_weights[0]\n",
    "    weights_1_2 = init_weights[1]\n",
    "    \n",
    "    print(\"Epoch:\", end = '')\n",
    "    \n",
    "    acc_history = [accuracy(x_train, y_train, (weights_0_1, weights_1_2))]\n",
    "    test_history = [accuracy(x_test, y_test, (weights_0_1, weights_1_2))]\n",
    "    \n",
    "    for i in range(number_of_epoch):\n",
    "        print(\".\", end = '')\n",
    "        \n",
    "        for input_data, expected_data in zip(train_data, train_labels):\n",
    "            # get prediction\n",
    "            layer_1, layer_2 = predict(input_data, (weights_0_1, weights_1_2))\n",
    "            \n",
    "            # dropout layer_1\n",
    "            dropout_mask = np.random.randint(2, size=len(layer_1))\n",
    "            layer_1 *= dropout_mask * 2\n",
    "            \n",
    "            # delta between prediction and expected result\n",
    "            # (1, 10) - (1, 10) -> (1, 10)\n",
    "            delta_layer_2 = layer_2 - expected_data\n",
    "            # delta on hidden layer, multiply output delta by weights between 1 and 2 layer\n",
    "            # (1, 10) dot (10, 30) * (1, 30) -> (1, 30)\n",
    "            delta_layer_1 = delta_layer_2.dot(weights_1_2.T) * relu_deriv(layer_1)\n",
    "            \n",
    "            # apply dropout to delta\n",
    "            delta_layer_1 *= dropout_mask\n",
    "            \n",
    "            # do the learning (backpropagation)\n",
    "            # alpha * (30, 1) dot (1, 10) -> (30, 10)\n",
    "            weights_1_2 = weights_1_2 - alpha * np.atleast_2d(layer_1).T.dot(np.atleast_2d(delta_layer_2))\n",
    "            # alpha * (783, 1) dot (1, 30) -> (783, 30)\n",
    "            weights_0_1 = weights_0_1 - alpha * np.atleast_2d(input_data).T.dot(np.atleast_2d(delta_layer_1))\n",
    "    \n",
    "        acc_history.append(accuracy(x_train, y_train, (weights_0_1, weights_1_2)))\n",
    "        test_history.append(accuracy(x_test, y_test, (weights_0_1, weights_1_2)))\n",
    "        print(test_history[-1])\n",
    "#       Early stopping\n",
    "#         if (acc_history[i+1] - acc_history[i]) < 0.0001:\n",
    "#             print(\"Early stopping!\")\n",
    "#             break\n",
    "\n",
    "    return (weights_0_1, weights_1_2), acc_history, test_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:.0.656\n",
      ".0.7279\n",
      ".0.758\n",
      ".0.7874\n",
      ".0.8103\n",
      ".0.8258\n",
      ".0.8358\n",
      ".0.8421\n",
      ".0.8491\n",
      ".0.8526\n",
      ".0.856\n",
      ".0.8575\n",
      ".0.8605\n",
      ".0.8645\n",
      ".0.8654\n",
      ".0.8669\n",
      ".0.8693\n",
      ".0.8724\n",
      ".0.8746\n",
      ".0.8747\n",
      ".0.8769\n",
      ".0.8782\n",
      ".0.8785\n",
      ".0.8808\n",
      ".0.878\n",
      ".0.8763\n",
      ".0.876\n",
      ".0.8788\n",
      ".0.8786\n",
      ".0.8804\n",
      ".0.8822\n",
      ".0.8817\n",
      ".0.88\n",
      ".0.8806\n",
      ".0.8833\n",
      ".0.8808\n",
      ".0.882\n",
      ".0.881\n",
      ".0.881\n",
      ".0.8791\n",
      ".0.8842\n",
      ".0.8823\n",
      ".0.8832\n",
      ".0.8823\n",
      ".0.8822\n",
      ".0.8845\n",
      ".0.8827\n",
      ".0.8828\n",
      ".0.8832\n",
      ".0.883\n",
      ".0.8813\n",
      ".0.8825\n",
      ".0.88\n",
      ".0.883\n",
      ".0.8818\n",
      ".0.8836\n",
      ".0.8817\n",
      ".0.8837\n",
      ".0.8804\n",
      ".0.8793\n",
      ".0.8812\n",
      ".0.8812\n",
      ".0.8802\n",
      ".0.8818\n",
      ".0.8806\n",
      ".0.8828\n",
      ".0.8789\n",
      ".0.8827\n",
      ".0.8815\n",
      ".0.8791\n",
      ".0.8799\n",
      ".0.8802\n",
      ".0.8807\n",
      ".0.8781\n",
      ".0.88\n",
      ".0.8807\n",
      ".0.8795\n",
      ".0.8804\n",
      ".0.8781\n",
      ".0.8803\n",
      ".0.8788\n",
      ".0.8785\n",
      ".0.8779\n",
      ".0.8789\n",
      ".0.8802\n",
      ".0.8777\n",
      ".0.8778\n",
      ".0.8791\n",
      ".0.8786\n",
      ".0.8787\n",
      ".0.881\n",
      ".0.8787\n",
      ".0.879\n",
      ".0.8782\n",
      ".0.8776\n",
      ".0.8794\n",
      ".0.8777\n",
      ".0.8776\n",
      ".0.8769\n",
      ".0.8779\n",
      ".0.8788\n",
      ".0.8786\n",
      ".0.879\n",
      ".0.8784\n",
      ".0.8775\n",
      ".0.8774\n",
      ".0.8775\n",
      ".0.8763\n",
      ".0.8778\n",
      ".0.8792\n",
      ".0.8776\n",
      ".0.8801\n",
      ".0.8763\n",
      ".0.8768\n",
      ".0.8775\n",
      ".0.8765\n",
      ".0.8761\n",
      ".0.8768\n",
      ".0.8764\n",
      ".0.8773\n",
      ".0.8755\n",
      ".0.8752\n",
      ".0.876\n",
      ".0.8759\n",
      ".0.876\n",
      ".0.8746\n",
      ".0.8758\n",
      ".0.8762\n",
      ".0.8755\n",
      ".0.8763\n",
      ".0.876\n",
      ".0.8755\n",
      ".0.8762\n",
      ".0.8755\n",
      ".0.8767\n",
      ".0.8754\n",
      ".0.8761\n",
      ".0.8758\n",
      ".0.8757\n",
      ".0.8756\n",
      ".0.8747\n",
      ".0.8755\n",
      ".0.875\n",
      ".0.8749\n",
      ".0.8747\n",
      ".0.8737\n",
      ".0.8741\n",
      ".0.8743\n",
      ".0.8737\n",
      ".0.8739\n",
      ".0.8752\n",
      ".0.8739\n",
      ".0.8744\n",
      ".0.8745\n",
      ".0.8727\n",
      ".0.8735\n",
      ".0.8742\n",
      ".0.8738\n",
      ".0.8749\n",
      ".0.8745\n",
      ".0.8731\n",
      ".0.8735\n",
      ".0.8734\n",
      ".0.8741\n",
      ".0.874\n",
      ".0.8733\n",
      ".0.873\n",
      ".0.8739\n",
      ".0.8735\n",
      ".0.8733\n",
      ".0.8729\n",
      ".0.873\n",
      ".0.8728\n",
      ".0.8737\n",
      ".0.8724\n",
      ".0.8719\n",
      ".0.8741\n",
      ".0.8735\n",
      ".0.8727\n",
      ".0.8727\n",
      ".0.8731\n",
      ".0.8726\n",
      ".0.8724\n",
      ".0.873\n",
      ".0.8724\n",
      ".0.8725\n",
      ".0.8726\n",
      ".0.8715\n",
      ".0.8731\n",
      ".0.8722\n",
      ".0.8723\n",
      ".0.8738\n",
      ".0.8712\n",
      ".0.8718\n",
      ".0.8715\n",
      ".0.8716\n",
      ".0.8718\n",
      ".0.8715\n",
      ".0.8722\n",
      ".0.8724\n",
      ".0.8718\n",
      ".0.8725\n",
      ".0.8722\n",
      ".0.8722\n",
      ".0.8726\n",
      ".0.8727\n",
      ".0.8726\n",
      ".0.872\n",
      ".0.8724\n",
      ".0.8722\n",
      ".0.8714\n",
      ".0.8723\n",
      ".0.8717\n",
      ".0.8706\n",
      ".0.8728\n",
      ".0.872\n",
      ".0.872\n",
      ".0.8723\n",
      ".0.8723\n",
      ".0.8718\n",
      ".0.8719\n",
      ".0.8707\n",
      ".0.8712\n",
      ".0.872\n",
      ".0.8723\n",
      ".0.8713\n",
      ".0.8714\n",
      ".0.8724\n",
      ".0.8721\n",
      ".0.872\n",
      ".0.8726\n",
      ".0.8724\n",
      ".0.8714\n",
      ".0.8718\n",
      ".0.8712\n",
      ".0.8702\n",
      ".0.8695\n",
      ".0.8701\n",
      ".0.8709\n",
      ".0.8711\n",
      ".0.87\n",
      ".0.871\n",
      ".0.8697\n",
      ".0.8703\n",
      ".0.8706\n",
      ".0.871\n",
      ".0.8712\n",
      ".0.871\n",
      ".0.8706\n",
      ".0.8706\n",
      ".0.8702\n",
      ".0.8703\n",
      ".0.8698\n",
      ".0.8713\n",
      ".0.8705\n",
      ".0.8705\n",
      ".0.8696\n",
      ".0.8699\n",
      ".0.8707\n",
      ".0.8706\n",
      ".0.8701\n",
      ".0.8702\n",
      ".0.8703\n",
      ".0.8701\n",
      ".0.8711\n",
      ".0.8702\n",
      ".0.8702\n",
      ".0.8703\n",
      ".0.8708\n",
      ".0.87\n",
      ".0.8709\n",
      ".0.8705\n",
      ".0.8697\n",
      ".0.8696\n",
      ".0.8702\n",
      ".0.8703\n",
      ".0.87\n",
      ".0.8696\n",
      ".0.8698\n",
      ".0.8702\n",
      ".0.8701\n",
      ".0.8694\n",
      ".0.8686\n",
      ".0.8697\n",
      ".0.8699\n",
      ".0.87\n",
      ".0.8693\n",
      ".0.8697\n",
      ".0.8697\n",
      ".0.869\n",
      ".0.8693\n",
      ".0.8703\n",
      ".0.8694\n",
      ".0.8691\n",
      ".0.8696\n",
      ".0.8694\n",
      ".0.8686\n",
      ".0.8689\n",
      ".0.869\n",
      ".0.8687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8687)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, acc_history, test_history = train(x_train, y_train, (init_weights_0_1, init_weights_1_2), 0.005, 300)\n",
    "\n",
    "(acc_history[-1], test_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1246e32b0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "\n",
    "# plot history and see generalization\n",
    "plot(list(range(len(acc_history))), acc_history, '-')\n",
    "plot(list(range(len(test_history))), test_history, 'g-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
