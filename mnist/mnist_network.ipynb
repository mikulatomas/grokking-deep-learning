{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_mnist import init, load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case that dataset is missing or pickle is broken uncomment this\n",
    "# init()\n",
    "\n",
    "x_train, y_train, _, _ = load()\n",
    "\n",
    "# take first 1000 samples\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "\n",
    "OUT_CLASSES = 10\n",
    "\n",
    "transformed_y_train = []\n",
    "\n",
    "for y_label in y_train:\n",
    "    zero = np.zeros((OUT_CLASSES,))\n",
    "    zero[y_label] = 1\n",
    "    transformed_y_train.append(zero)\n",
    "\n",
    "y_train = transformed_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_data, weights):\n",
    "    return input_data.dot(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13397.12439459, 13972.57462143, 14244.06852601, 12678.91260581,\n",
       "       13801.35334837, 13002.50110294, 14132.42518159, 13567.25706641,\n",
       "       14643.60908063, 14254.58873332])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(x_train[0], init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, train_labels, init_weights, alpha, number_of_epoch):\n",
    "    weights = init_weights\n",
    "    print(\"Epoch:\", end = '')\n",
    "    \n",
    "    for i in range(number_of_epoch):\n",
    "        print(\".\", end = '')\n",
    "        for input_data, expected_data in zip(train_data, train_labels):\n",
    "            # get prediction\n",
    "            result = predict(input_data, weights)\n",
    "\n",
    "            # delta between prediction and expected result -> vector\n",
    "            delta = result - expected_data\n",
    "\n",
    "            # mean square error -> vector\n",
    "            error = delta ** 2\n",
    "\n",
    "            # cast delta to matrix\n",
    "            delta_matrix = np.matrix(delta)\n",
    "            # cast input to matrix (numpy stuff)\n",
    "            input_matrix = np.matrix(input_data).T\n",
    "\n",
    "            a = alpha * input_matrix.dot(delta_matrix)\n",
    "\n",
    "            # update weights via gradient descent\n",
    "            weights = np.array(\n",
    "                weights - alpha * input_matrix.dot(delta_matrix))\n",
    "    #         print(weights - alpha * input_matrix.dot(delta_matrix))\n",
    "\n",
    "    print()\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:..........\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.90948716, 0.29885556, 0.25093274, ..., 0.03349662, 0.53575219,\n",
       "        0.7690596 ],\n",
       "       [0.01490249, 0.90066649, 0.55276528, ..., 0.8995095 , 0.75117191,\n",
       "        0.88068737],\n",
       "       [0.58961693, 0.93514663, 0.48451594, ..., 0.11054576, 0.74694145,\n",
       "        0.11279574],\n",
       "       ...,\n",
       "       [0.7013639 , 0.04110348, 0.16776304, ..., 0.50194124, 0.27198701,\n",
       "        0.97137613],\n",
       "       [0.93434716, 0.4923438 , 0.7405907 , ..., 0.83398103, 0.75831871,\n",
       "        0.89399657],\n",
       "       [0.76927339, 0.41875878, 0.84552317, ..., 0.15929538, 0.07795588,\n",
       "        0.52938311]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_weights = np.random.rand(x_train.shape[1], 10)\n",
    "\n",
    "weights = init_weights\n",
    "\n",
    "weights = train(x_train, y_train, weights, 0.0000001, 10)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8701"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = 0\n",
    "for input_, label in zip(x_train, y_train):\n",
    "    if np.argmax(predict(input_, weights)) == np.argmax(label):\n",
    "        match += 1\n",
    "        \n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit5f89873530d548e587a26d547ff3b9fd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
